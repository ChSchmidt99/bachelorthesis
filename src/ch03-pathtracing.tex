\section{Path Tracing}
\subsection{Algorithm}
At the core of any ray tracing approach is the concept of a ray, usually in three-dimensional space. In this work the following representation is used.
\[P(t)=O+td\]
% TODO: Introduce math notation
Where the origin $O$ is some point within the scene space and the direction $d$ is some vector along which the ray travels in a straight line. Points along this line can be described using the distance $t$, with $P(0)=O$ and $P(1)=O+d$. 
% TODO: Add Ray tracing Figure
As illustrated in figure 1, this concept can be used to construct images. Rays are cast into a scene, originating at some common eye point and intersecting each pixel in the image plane to find its corresponding color. The first ray casting algorithm using such a technique was proposed by Appel\cite{appel1968}, only considering primary intersections and shadow rays towards a light source to determine whether a point is illuminated or not. Whitted\cite{whitted_improved_1980} expanded on that approach by introducing an algorithm that, upon finding an object intersection, generates secondary rays influencing the final pixel color. In addition to the previously mentioned shadows, these secondary rays allow rendering of reflections and refractions by recursively casting new rays in the reflection direction and blending all results. 
% TODO: Is it really more common?
A more common approach, especially in film and visual effects\cite{keller2015path_tracing_revolution}, is a closely related concept called path tracing\cite{kajiya_rendering_1986}. Instead of evaluating a single ray per pixel, multiple samples with slight offsets and random scattering are used to more accurately simulate light transport through a scene and approximate the rendering equation also introduced by Kajiya. Path tracing is a global illumination solution and thus produces more realistic results, while also allowing accurate rendering of distribution effects\cite{cook_distributed_1984} and inherently solving the problem of aliasing. 
\subsection{Optimizations}
The issue with path tracing is, that it requires many samples to produce plausible results as images without sufficient samples suffer from high-frequency noise. Tracing such a number of rays, while also maintaining interactive frame rates, simply is not possible at the moment and probably will not be in the foreseeable future, especially with Moore's law converging to an end. As a result, real-time path tracing would not be possible without optimizations reducing the rendering time by several orders of magnitudes. 
\subsubsection{Denoising}
A big leap towards reducing that number was achieved in recent years through the introduction of more advanced denoising techniques. Through denoising, the required samples-per-pixel can be reduced to a significantly lower number, going down to single sample with some techniques. Schied et al.~\cite{schied_spatiotemporal_2017} combines path tracing output with previous frame data and a noise free G-buffer generated using a rasterization pass, to feed a wavelet filter and produce a denoised, temporally stable sequence of images using only one path-per-pixel. Chaitanya et al.~\cite{chaitanya_interactive_2017} applies machine learning to the problem by using a convolutional neural network to map noisy input images to noise-free output. Other real-time reconstruction filters\cite{mara17towards,koskela2019bmfr} achieve similar results and opened up the door for real-time path tracing in the first place. However, denoising was not the focus of my work and will not be mentioned in the remainder of this thesis. Subsequently, the described path tracer produces noisy one sample-per-pixel output leaving the choice of denoising technique open, even though applying any denoising technique would be an interesting task for some future work.
% TODO: Metion DLSS?
% TODO: Add paragraph about importance sampling?
\subsubsection{Acceleration Data Structures}
Another essential optimization technique, and also the focus of this thesis, is improving path tracing itself by using acceleration data structures. These are used to arrange scene primitives efficiently in a hierarchical data structure, so that instead of requiring intersection tests with every single primitive, only a reduced number of checks is necessary. In essence, there are two approaches for creating such acceleration structures\cite{macDonald1988space}, space subdivision and object subdivision.
The former works by splitting the scene space recursively into smaller subregions, either by generating binary trees, first proposed by Fuchs et al.~\cite{fuchs1980bsp}, or trees with higher branching factors often referred to as k-d trees. While k-d trees generally have a lower depth, binary trees allow for simpler traversal, as only a two-way decision is needed at each step. 
Glassner\cite{glassner_space_1984} described one of the earliest approaches for generating octrees that, for each recursive step, splits the given subspace at the spatial median along all three axis, resulting into eight new subregions. Kaplan\cite{kaplan_use_1985} expanded on that idea by introducing a very similar implementation utilizing binary trees instead of octrees. Fujimoto et al.~\cite{fujimoto_arts_1986}, while also using octrees, achieved a significant speed improvement by using incremental integer arithmetic to optimize the traversal algorithm. 
% TODO: Mention advantages and disadvantages of k-d tree
% TODO: Mention more recent and state-of-the-art kd-tree approaches

% TODO: Introduce BVH and compare to k-d tree

