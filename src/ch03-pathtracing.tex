\section{Path Tracing}
\subsection{Algorithm}
At the core of any ray tracing approach is the concept of a ray, usually in three-dimensional space. In this work the following representation is used.
\[P(t)=O+td\]
% TODO: Introduce math notation
Where the origin $O$ is some point within the scene space and the direction $d$ is some vector along which the ray travels in a straight line. Points along this line can be described using the distance $t$, with $P(0)=O$ and $P(1)=O+d$. 
% TODO: Add Ray tracing Figure
As illustrated in figure 1, this concept can be used to construct images. Rays are cast into a scene, originating at some common eye point and intersecting each pixel in the image plane to find its corresponding color. The first ray casting algorithm using such a technique was proposed by Appel\cite{appel1968}, only considering primary intersections and shadow rays towards a light source to determine whether a point is illuminated or not. Whitted\cite{whitted_improved_1980} expanded on that approach by introducing an algorithm that, upon finding an object intersection, generates secondary rays influencing the final pixel color. In addition to the previously mentioned shadows, these secondary rays allow rendering of reflections and refractions by recursively casting new rays in the reflection direction and blending all results. 
% TODO: Is it really more common?
A more common approach, especially in film and visual effects\cite{keller2015path_tracing_revolution}, is a closely related concept called path tracing\cite{kajiya_rendering_1986}. Instead of evaluating a single ray per pixel, multiple samples with slight offsets and random scattering are used to more accurately simulate light transport through a scene and approximate the rendering equation also introduced by Kajiya. Path tracing is a global illumination solution and thus produces more realistic results, while also allowing accurate rendering of distribution effects\cite{cook_distributed_1984} and inherently solving the problem of aliasing. 
\subsection{Optimizations}
The issue with path tracing is, that it requires many samples to produce plausible results as images without sufficient samples suffer from high-frequency noise. Tracing such a number of rays, while also maintaining interactive frame rates, simply is not possible at the moment and probably will not be in the foreseeable future, especially with Moore's law converging to an end. As a result, real-time path tracing would not be possible without optimizations reducing the rendering time by several orders of magnitudes. A big leap towards reducing that number was achieved in recent years through the introduction of more advanced denoising techniques. Through denoising, the required samples-per-pixel can be reduced to a significantly lower number, going down to single sample with some techniques. Schied et al.\cite{schied_spatiotemporal_2017} combines path tracing output with previous frame data and a noise free G-buffer generated using a rasterization pass, to feed a wavelet filter and produce a denoised, temporally stable sequence of images using only one path-per-pixel. Chaitanya et al.\cite{chaitanya_interactive_2017} applies machine learning to the problem by using a convolutional neural network to map noisy input images to noise-free output. Other real-time reconstruction filters\cite{mara17towards,koskela2019bmfr} achieve similar results and opened up the door for real-time path tracing in the first place. However, denoising was not the focus of my work and will not be mentioned in the remainder of this thesis. Subsequently, the described path tracer produces noisy one sample-per-pixel output leaving the choice of denoising technique open, even though applying any denoising technique would be an interesting task for some future work.
% TODO: Add paragraph about importance sampling?
