\section{Interactive Path Tracer}
This section provides a broad overview over the interactive path tracer written for this thesis including the BVH construction algorithm called PHR as first introduced by Hendrich et al.~\cite{hendrich_parallel_2017}. Furthermore, the contributions made by this thesis are explained in more detail. These contributions include applying PHR to an interactive path tracer and introducing two approaches for optimizing the hyperparameters utilized by the algorithm in real-time. 

\subsection{Project Environment}
The fundamental point of this thesis was to write and optimize a CPU path tracer. First and foremost, to see how well path tracing performs on CPUs compared to GPUs. In general, CPUs are designed to execute serial instructions on an intermediate amount of data very fast, while GPUs are optimized to process instructions in parallel using little memory but maximizing throughput. Consequently, CPUs consist of few powerful cores, use pipelining, branch prediction, out-of-order execution and utilize a bigger coherent cache while GPUs consist of many weaker cores and are optimized to run the graphics pipeline. This makes them perform very well with highly coherent work. Path tracing however, can often be very incoherent as rays might be scattered in all kinds of directions hitting very different primitives. In order to find ray intersections it is also necessary to have the whole acceleration structure in memory, which might be an issue with the limited GPU memory. Lastly, data transfer between CPU and GPU is costly and can be avoided by processing data directly on the CPU. 

Considering those aspects, it is an interesting topic to implement and benchmark a CPU path tracer.

Another though was that, given sufficient performance, the CPU path tracer could be used in hybrid with GPUs to increase their performance. % Mention UE5 hybrid

And finally, the goal was to keep all ideas and algorithms as general as possible and not bound to a specific implementation.

The path tracer is written in the programming language Go, which has a few advantages and disadvantages. One of the main reasons for using Go was the built in thread management in the form of go routines. % TODO: Explain go routines
In addition to keeping concurrency efficient, this keeps the source code very readable tieing in very well with the overall readability of Go. Another bonus the language offeres is great benchmarking support as part of the language.

The above listed advantages were enough to choose the language, however, there are still a few shortcomings. The main issue is the performance of the language. Even though Go allows to write code somewhat close to the system, it still is a rather high level language. The built in garbage collector might be very well optimized, but having a garbage collector at all is a substential performance sink and the Go compiler favors compile time over execution performance. Some of those problems can be optimized, for example the whole path tracer was written with a 'zero alloc' approach, reusing structs where possible and using C style pointer parameter returns, but other languages like C or Rust could have performed favorably.

\subsection{Path Tracer}
The renderer itself supports two types of primitives. Spheres, as they have the simplest intersection function and triangles, 
% TODO: Mention intersection algorithms
as most geometry can be represented or at least approximated using triangles. Each primitive can have an associated material. Those are currently limited to three different ones, all having an albedo color value and a scatter function for incoming rays. Diffuse materials scatter rays in a random direction within a unit sphere. Reflective materials reflect the ray in the reflection direction and a certain random deviation is added depending on a diffussion coefficient. Refractive materials utilize snell's law to represent glass objects and other dielectrics. In addition to those materials, there are also light sources, which instead of scattering rays add color to them. 

% TODO: Check if that's actually the way in the final project
Rendering a frame is done line by line utilizing the worker pattern. $k$ threads render a single line and then wait for a new 
% TODO: Mark code in text?
line using Go channels. A pixel is colored by casting a new ray with a slightly offset origin within said pixel and a direction directed towards the according pixel in the image plane. The closest intersection is determined by traversing the 
% TODO: Add see section
scene's BVH\nameref{traversal} returning a hit record containing relevant information like intersection point, normal and material at said point. If no intersection is found, the pixel is colored in the color specified by the miss shader, otherwise the closest hit shader will be called with the intersection information. The closest hit shader casts a new ray from the intersection point depending on how the material at given point scatters and calls itself recursively if a new intersection is found and the maximum depth has not been reached. At each step, emitted light will be added to the pixel and multiplied by the materials albedo. Each thread reuses a single ray and hit structure to avoid allocating additional memory.
\subsection{Progressive Hierarchical Refinement}
\subsubsection{Overview}
% PHR Overview
Bounding volume hierarchies are constructed using progressive hierarchical refinement (PHR) as proposed by Hendrich et al.\cite{hendrich_parallel_2017}. As previously established, applying full sweep SAH to all scene primitives is magnitudes too slow. PHR tackles this problem by first constructing an auxiliary BVH, which then serves as a hierarchy to find much smaller sets of nodes on which full sweep SAH can be applied fairly inexpensively. The two resulting cuts are then refined, meaning that some nodes within those cuts are replaced by their children, if their bounding box surface area is above a certain threshold. Afterwards, the algorithm is applied recursively to the refined cuts until the full BVH is constructed. 

% Auxiliary BVH
\subsubsection{Auxiliary Bounding Volume Hierarchy}
% Context on LBVH
As the auxiliary BVH is only needed as a description of the scene's hierarchy, construction speed is the main priority. Multiple fast builders have been tested in the original paper\cite{hendrich_parallel_2017}, but linear bounding volume hierarchies (LBVH) turned out to be the best choice. LBVH was first proposed by Lauterbach et al.\cite{lauterbach09lbvh} as a top-down algorithm that assigns Morton codes to all primitives and then builds the tree as a binary radix tree. The algorithm itself has since been improved multiple times\cite{karras12lbvh,apetrei14lbvh,chitalu20lbvh} making it one of the fastest approaches to date\cite{meister21survey}. However, these approaches exploit the massive parallelism GPUs can provide by building the BVH in a bottom up fashion, which makes less sense on the limited amount of cores CPUs provide. Consequently, the approach I used is closer to the top-down approach proposal\cite{lauterbach09lbvh} with a few adjustments. 

Construction of the auxiliary BVH starts off by sorting all primitives along a Morton curve\cite{morton66curve}. This space filling curve subdivides the scene space into a uniform grid resulting in Morton codes of fixed length. A 2D example using 2 bits per dimension can be seen in figure...% TODO: Add morton figure and adjust text

Computation of Morton codes is done fairly efficiently by interleaving successive bits of the primitives' quantized bounding box 
centroids like follows: 
\[P=(3,7,5)=(011,111,101)=(110011111)=415\] % TODO: Adjust example to figure and color bits

Morton codes are assigned in parallel by processing $[n/t]$ primitives per thread, with $n$ being the number of scene primitives and $t$ being the number of threads. Afterwards, the primitives are sorted according to their Morton code using a parallel bucket sort implementation. In each thread, $k=2^{12}$ empty buckets are created and filled with $[n/t]$ primitives. By using individual buckets for each thread, no further synchronization necessary for the bucketing. However, an atomic counter is used to keep track of the total number of primitives in each bucket across all threads, which is then used to find the intervals in the original slice each bucket occupies. After bucketing is finished, all non-empty buckets with the same index are merged and directly written in the mentioned interval in the input slice and sorted in place using Go's built-in sort function. This step is also done in parallel by utilizing the worker pattern to send buckets with the same index to each thread until all buckets have been processed.

The corresponding BVH can be constructed by recursively splitting the set of primitives at the highest bit withing the current interval. This is done using a Go channel and entries representing a node in the finished tree. Each thread fetches such a node and finds the split in the corresponding slice by applying linear search. If the node does not become a leaf, the resulting cuts are sent to the channel to be processed by idle threads.

Finally, the bounding boxes of the tree need to be updated. This is done in parallel by starting at the trees leaves and traversing towards the root. Whenever a thread visits a node the bounding box is updated using the child or primitive bounding boxes. Then the parents atomic counter is incremented and if all children are set, the thread also processes the parent. Otherwise, the thread fetches an unprocessed leaf from a queue. The same procedure is executed when refitting the LBVH on scene changes. 
\subsubsection{Algorithm}




PHR beginns by finding a set of nodes that seperate root and leaves in the auxiliary LBVH. Nodes are selected by inserting the BVHs root into a priority queue. Items within that queue are processed by checking the surface area of their bounding boxes against a given threshold. If the surface area is below that threshold, the node is added to the initial cut, otherwise its children are inserted into the priority queue. The resulting cut is several magnitudes below the full primitive count and can be processed inexpensively using full sweep SAH.

Splitting a cut using SAH beginns by sorting nodes along one axis and sweeping along this axis, calculating the cost using following equation:

\[C(i)=S_L(i)n_L(i)+S_R(i)n_R(i)\]

With $S_L(i)$ and $S_R(i)$ being the bounding boxes surface areas of the left and right subsets and $n_L(i)$ and $n_R(i)$ being the nuber of nodes in the corresponding subtrees.

This process is repeated for all three axis and the lowest cost is chosen to create the two new cuts. These cuts are then refinded, using an adaptive threshold. If a nodes surface are is below this threshold, it is kept within the cut as is, otherwise it is replaced by its children. 
% TODO: Adaptive Threshold
This adaptive threshold is given as 
\[t_d = S /{2^{\alpha d + \delta}}\]
with $S$ being the surface are of the scene bounding box and $d$ the current depth in the tree. $\alpha$ and $\delta$ are parameters that will be elaborated in more detail in section \nameref{adaptive threshold}.
The adaptive threshold shrinks further down the tree making cuts smaller as the pay off of using SAH is higher in the upper levels. Refined cuts are then processed recursively until the whole tree is built. 

Additionally, the tree can be build using higher branching factors, which can improve performance even further. To do so, nodes are only formed, once a sufficient ammount of children is available. Otherwise, the biggest existing cut is processed. 

\subsubsection{Traversal}
\label{traversal}
Bounding volume hierarchies are traversed using a stack starting with the trees root. While the stack is not empty, nodes are popped and checked for intersections. If an intersection is found, the nodes children are pushed on top, otherwise the node is discarted. In case a leaf node is encountered, all primitives will be checked and the closest intersection is recorded. Once the stack is empty, the closest intersection found is returned. 

\subsubsection{Integration into Interactive Path Tracing}
% TODO: Describe integration of PHR into interactive path tracer
An approach for integrating PHR into interactive applications was mentioned in the original paper\cite{hendrich_parallel_2017}, but its validation remained an open topic. The idea was to only build the auxiliary BVH once in the beginning and then refit it very efficiently between frames. Refitting works in parallel by starting at the leaves of the LBVH and computing the new bounding box before traversing up the tree. Each branch is equipped with an atomic counter and the second thread visiting each node will update its bounding box. The refined PHR BVH is then computed using the refitted LBVH version. 

\subsubsection{Adaptive Threshold}
\label{adaptive threshold}
The adaptive threshold depends on two hyperparameters, where $\alpha$ determines how quickly cuts shrink towards the bottom of the tree and $\delta$ determines how big the initial cut is. These parameters can be set to adjust the trade off between build time and trace performance. However, the optimal parameters can differ between scenes and view points, especially in interactive path tracing. 


% TODO: Describe in more detail

Consequently, to unlock the full potential of PHR these parameters need to be adjusted depending on the current state of the scene. To do so, I implemented the optimization approaches grid search and bayesian optimization and compared them.

Grid search is the brute force approach, where a number of possible values is choosen for each parameter to then check all possible combinations. Even though grid search delivers fairly good results, it would usually be too costly for such a time critical task. In this task however, only two parameters need to be optimized and the search space is relatively small making grid search a viable approach. 

A more efficient approach compared to grid search is Bayesian optimization. I used Bayesian optimization based on a Gaussian process, which means that a posterior distribution of functions describing the relation between the parameters is created. First, the parameters are chosen by random and evaluated. The Gaussian process is then fitted to those samples and using the posterior distribution the next point worth exploring is selected. In the end, I used Upper Confidence Bound as exploration strategy, as this approach produced the best results. 

The optimized function is a simple weighted sum between the number of nodes in the resulting BVH and an approximated intersection count. The number of nodes is a rough estimate of the construction time, as actually taking the construction time might result in unstable results. Assuming that more nodes equal a longer build time is fair, as it takes a certain time to compute each node and bigger nodes, where SAH takes the longest, also result in more child nodes further down the tree. An approximation of the trace performance is sampled by tracing the same view point with a relatively smaller resolution. Only primary rays are recorded to further increase performance. 
Using a weighted sum to evaluate the parameter performance in itself adds new parameters. However, the parameters introduced by the evaluation function are not dependend on the scene. % TODO: Adjust wheights according to frame time?
% TODO: Problem: alpha+ delta not correlating with build time, other metric needed 